{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(test_size:float=0.3):\n",
    "    \"\"\"\n",
    "    Load test iris dataset. Split into X_train, X_test, y_train, y_test.\n",
    "    \n",
    "    :param test_size: Percentage of dataset to use for test set.\n",
    "    \n",
    "    :returns:         X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X, y = load_iris(return_X_y=True, as_frame=True)\n",
    "    return train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_class(str:str):\n",
    "    \"\"\"\n",
    "    Turns a string into Python class. Used to dynamically load Sklearn model classes.\n",
    "    Note: Desired class must be imported at top of script.\n",
    "    \n",
    "    :param str: String to dynamically load as Python class.\n",
    "    \n",
    "    :returns:   Python class corresponding to string.\n",
    "    \"\"\"\n",
    "    return eval(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_class:str, model_params:dict):\n",
    "    \"\"\"\n",
    "    Build Sklearn model of certain type with parameters.\n",
    "    \n",
    "    :param model_class:  Sklearn class to create.\n",
    "    :param model_params: Dict of model parameters to use.\n",
    "    \n",
    "    :returns:            Newly built sklearn model.\n",
    "    \"\"\"\n",
    "    model_class = str_to_class(model_class)\n",
    "    return model_class(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    hyperparameters:dict,\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series\n",
    "):\n",
    "    \"\"\"\n",
    "    Train Sklearn model with random hyperparameter search.\n",
    "    \n",
    "    :param model:           Sklearn model to train.\n",
    "    :param hyperparameters: Hyperparameter grid to search.\n",
    "    :param X_train:         Training data.\n",
    "    :param y_train:         Training labels.\n",
    "    \n",
    "    :returns:               Best trained Sklearn model.\n",
    "    \"\"\"\n",
    "    clf = RandomizedSearchCV(model, hyperparameters, random_state=0)\n",
    "    search = clf.fit(X_train, y_train)\n",
    "    return search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test: pd.DataFrame, y_test: pd.Series) -> dict:\n",
    "    \"\"\"\n",
    "    Evaluates trained SKlearn model with common metrics.\n",
    "    \n",
    "    :param model:  Trained Sklearn model.\n",
    "    :param X_test: Test data to evaluate with.\n",
    "    \n",
    "    :returns:      Dict of evaluation metrics.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    return {\n",
    "        \"accuracy\" : accuracy_score(y_test, y_pred),\n",
    "        \"f1\" : f1_score(y_test, y_pred, average=\"micro\"),\n",
    "        \"precision\" : precision_score(y_test, y_pred, average=\"micro\"),\n",
    "        \"recall\" : recall_score(y_test, y_pred, average=\"micro\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model_config: dict):\n",
    "    \"\"\"\n",
    "    Main training function. Loads data, trains models using specified\n",
    "    classes/parameters/hyperparameters, evaluates models, and exports\n",
    "    models to disk.\n",
    "    \n",
    "    :param model_config: Dict of model classes and corresponding parameters\n",
    "                         and hyperparameters to use while training.\n",
    "    \"\"\"\n",
    "    # Get datasets\n",
    "    X_train, X_test, y_train, y_test = get_data()\n",
    "    \n",
    "    # For all models in config\n",
    "    for name, config in model_config.items():\n",
    "\n",
    "        # Build base model\n",
    "        print(f\"Building: {name}\")\n",
    "        model = build_model(model_class=name, model_params=config[\"params\"])\n",
    "\n",
    "        # Train model with hyperparameter tuning\n",
    "        print(f\"Training: {name}\")\n",
    "        model = train_model(model, config[\"hyperparameters\"], X_train, y_train)\n",
    "        print(f\"Best parameters: {model.get_params()}\")\n",
    "\n",
    "        # Evaluate model\n",
    "        print(f\"Evaluating: {name}\")\n",
    "        metrics = evaluate_model(model, X_test, y_test)\n",
    "        print(f\"Evaluation metrics: {metrics}\")\n",
    "\n",
    "        # Export model to disk\n",
    "        print(f\"Saving: {name}\")\n",
    "        pickle.dump(model, open(f\"{name}.pkl\", 'wb'))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"params\" : {'solver': 'saga', 'tol': 0.01, 'max_iter': 200, 'random_state': 0},\n",
    "        \"hyperparameters\" : {\"penalty\": ['l2', 'l1'], \"C\" : [0.6, 0.8, 1.0, 1.1, 1.2]}\n",
    "    },\n",
    "    \"RandomForestClassifier\" : {\n",
    "        \"params\" : {\"max_depth\": 2, \"random_state\": 0},\n",
    "        \"hyperparameters\" : {\"n_estimators\" : [10, 50, 100, 200], \"criterion\": [\"gini\", \"entropy\"]}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building: LogisticRegression\n",
      "Training: LogisticRegression\n",
      "Best parameters: {'C': 0.6, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 200, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 0, 'solver': 'saga', 'tol': 0.01, 'verbose': 0, 'warm_start': False}\n",
      "Evaluating: LogisticRegression\n",
      "Evaluation metrics: {'accuracy': 0.9555555555555556, 'f1': 0.9555555555555556, 'precision': 0.9555555555555556, 'recall': 0.9555555555555556}\n",
      "Saving: LogisticRegression\n",
      "\n",
      "Building: RandomForestClassifier\n",
      "Training: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/User/.pythonlibs/jupyter-nick/lib/python3.7/site-packages/sklearn/model_selection/_search.py:289: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "Evaluating: RandomForestClassifier\n",
      "Evaluation metrics: {'accuracy': 0.9333333333333333, 'f1': 0.9333333333333333, 'precision': 0.9333333333333333, 'recall': 0.9333333333333333}\n",
      "Saving: RandomForestClassifier\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(model_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
