{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlrun: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudpickle import load\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "import mlrun\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "class ClassifierModel(mlrun.serving.V2ModelServer):\n",
    "    def load(self):\n",
    "        \"\"\"load and initialize the model and/or other elements\"\"\"\n",
    "        model_file, extra_data = self.get_model('.pkl')\n",
    "        self.model = load(open(model_file, 'rb'))\n",
    "\n",
    "    def predict(self, body: dict) -> List:\n",
    "        \"\"\"Generate model predictions from sample.\"\"\"\n",
    "        feats = np.asarray(body['inputs'])\n",
    "        X = feats[:, :-1]\n",
    "        y = feats[:, -1]\n",
    "        y_pred = self.model.predict(X)\n",
    "\n",
    "        return {\n",
    "            \"prediction\": y_pred.tolist(),\n",
    "            \"metrics\" : {\n",
    "                \"accuracy\" : accuracy_score(y, y_pred),\n",
    "                \"f1\" : f1_score(y, y, average=\"micro\"),\n",
    "                \"precision\" : precision_score(y, y_pred, average=\"micro\"),\n",
    "                \"recall\" : recall_score(y, y_pred, average=\"micro\"),\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlrun: end-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.serving.states.TaskStep at 0x7f20b1d73150>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import code_to_function, auto_mount\n",
    "\n",
    "serving_fn = code_to_function(\n",
    "    name='model-server',\n",
    "    project=\"royal-cyber\",\n",
    "    kind='serving',\n",
    "    image='mlrun/mlrun'\n",
    ").apply(auto_mount())\n",
    "\n",
    "serving_fn.spec.default_class = 'ClassifierModel'\n",
    "\n",
    "serving_fn.add_model('lr', model_path=\"store://models/royal-cyber/my-training-job-tracking-main_LogisticRegression_model#0:latest@32c8cd1816a14b5eb49d99ab92521b08\")\n",
    "serving_fn.add_model('rf', model_path=\"store://models/royal-cyber/my-training-job-tracking-main_RandomForestClassifier_model#0:latest@32c8cd1816a14b5eb49d99ab92521b08\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-08-25 21:04:44,565 [info] Starting remote function deploy\n",
      "2021-08-25 21:04:44  (info) Deploying function\n",
      "2021-08-25 21:04:44  (info) Building\n",
      "2021-08-25 21:04:44  (info) Staging files and preparing base images\n",
      "2021-08-25 21:04:44  (info) Building processor image\n",
      "2021-08-25 21:04:46  (info) Build complete\n",
      "2021-08-25 21:04:54  (info) Function deploy complete\n",
      "> 2021-08-25 21:04:55,157 [info] function deployed, address=default-tenant.app.us-sales-eks.iguazio-cd0.com:30624\n"
     ]
    }
   ],
   "source": [
    "function_address = serving_fn.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"inputs\": [[5.2, 2.7, 3.9, 1.4, 1], [6.5, 3.2, 5.1, 2.0, 2], [6.1, 2.9, 4.7, 1.4, 1], [4.6, 3.2, 1.4, 0.2, 0], [5.5, 3.5, 1.3, 0.2, 0], [5.3, 3.7, 1.5, 0.2, 0], [4.8, 3.4, 1.6, 0.2, 0], [6.5, 3.0, 5.2, 2.0, 2], [5.1, 3.4, 1.5, 0.2, 0], [4.7, 3.2, 1.3, 0.2, 0], [5.9, 3.2, 4.8, 1.8, 1], [6.4, 3.2, 5.3, 2.3, 2], [6.3, 3.3, 4.7, 1.6, 1], [4.8, 3.1, 1.6, 0.2, 0], [5.8, 2.6, 4.0, 1.2, 1], [4.9, 3.6, 1.4, 0.1, 0], [6.3, 2.9, 5.6, 1.8, 2], [6.2, 2.9, 4.3, 1.3, 1], [6.6, 3.0, 4.4, 1.4, 1], [6.7, 3.1, 4.4, 1.4, 1]]}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True, as_frame=True)\n",
    "X_test = pd.concat([X, y.to_frame()], axis=1).sample(frac=1).head(20)\n",
    "\n",
    "data = json.dumps({\"inputs\" : X_test.to_dict(orient=\"split\")[\"data\"]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'bd06550b-e002-4c4a-b7dc-11160e87dc08', 'model_name': 'lr', 'outputs': {'prediction': [1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 2, 1, 1, 1], 'metrics': {'accuracy': 0.95, 'f1': 1.0, 'precision': 0.95, 'recall': 0.95}}}\n",
      "{'id': 'a5348347-6b4a-4f37-ab62-ebb800f2d45c', 'model_name': 'lr', 'outputs': {'prediction': [1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 2, 1, 1, 1], 'metrics': {'accuracy': 0.95, 'f1': 1.0, 'precision': 0.95, 'recall': 0.95}}}\n",
      "{'id': '70e58c4d-b04d-4a86-95e2-5fea08d308e7', 'model_name': 'rf', 'outputs': {'prediction': [1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 2, 1, 1, 1], 'metrics': {'accuracy': 0.95, 'f1': 1.0, 'precision': 0.95, 'recall': 0.95}}}\n",
      "{'id': '27355681-2484-4ab6-84d0-09c8f5c54ab7', 'model_name': 'rf', 'outputs': {'prediction': [1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 2, 1, 1, 1], 'metrics': {'accuracy': 0.95, 'f1': 1.0, 'precision': 0.95, 'recall': 0.95}}}\n"
     ]
    }
   ],
   "source": [
    "for model in [\"lr\", \"rf\"]:\n",
    "    # Inference via serving function\n",
    "    print(serving_fn.invoke(f'/v2/models/{model}/infer', data))\n",
    "    \n",
    "    # Inference via HTTP post request\n",
    "    print(requests.post(url=f\"{function_address}/v2/models/{model}/infer\", data=data).json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
