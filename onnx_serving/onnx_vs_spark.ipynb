{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfeb38b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from onnxmltools import convert_sparkml\n",
    "from onnxmltools.convert.sparkml.utils import buildInitialTypesSimple\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515b8520",
   "metadata": {},
   "source": [
    "### Setup Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41b612ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()\\\n",
    "        .setMaster(\"local[*]\")\\\n",
    "        .set(\"spark.cores.max\", \"2\")\\\n",
    "        .setAppName(\"Model Inferencing\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "spark = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b9d1de",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e190916",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = pd.read_parquet(\"training_set.parquet\").drop([\"isFraud\", \"FROMACCTNBR\"], axis=1)\n",
    "df = spark.read.parquet(\"v3io://users/nick/onnx/training_set.parquet\")\n",
    "df = df.drop(\"isFraud\")\n",
    "df = df.drop(\"FROMACCTNBR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac2012",
   "metadata": {},
   "source": [
    "### Load Spark Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5eb4265",
   "metadata": {},
   "outputs": [],
   "source": [
    "numericCols = [\n",
    "     'CARDTXNNBR',\n",
    "     'isPinned',\n",
    "     'TXNAMT',\n",
    "     '2ndLastTrxnAmnt',\n",
    "     'scenario1_withoutMerchant',\n",
    "     'scenario1_withMerchant',\n",
    "     'isGoogle',\n",
    "     'isPlayStation',\n",
    "     'isAmazon',\n",
    "     'isApple',\n",
    "     'isMicrosoft',\n",
    "     'isFbPay',\n",
    "     'isCashApp',\n",
    "     'isPaypal',\n",
    "     'isVenmo',\n",
    "     'isWellumpay',\n",
    "     'secanrio3NoOfTrxn',\n",
    "     'secanrio3_Label',\n",
    "     'scenario4_2trxn',\n",
    "     'scenario5_2trxn',\n",
    "     'diffLastTrxn',\n",
    "     'isNewCustomer']\n",
    "assembler = VectorAssembler(inputCols=numericCols, outputCol=\"features\").setHandleInvalid(\"skip\")\n",
    "model = RandomForestClassificationModel.load(\"v3io://users/nick/onnx/model_v2\")\n",
    "pipeline = Pipeline(stages=[assembler, model])\n",
    "pipeline_model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e60da8e",
   "metadata": {},
   "source": [
    "### Export Pipeline to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fc2c745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/User/.pythonlibs/jupyter-nick/lib/python3.7/site-packages/onnxconverter_common/topology.py:702: UserWarning: Some input names are not compliant with ONNX naming convention: ['2ndLastTrxnAmnt']\n",
      "  warnings.warn('Some input names are not compliant with ONNX naming convention: %s' % invalid_name)\n",
      "The maximum opset needed by this model is only 1.\n",
      "The maximum opset needed by this model is only 4.\n"
     ]
    }
   ],
   "source": [
    "initial_types = buildInitialTypesSimple(df)\n",
    "onnx_model = convert_sparkml(pipeline_model, 'Pyspark model', initial_types, spark_session = spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b4b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"model.onnx\"), \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a43e3",
   "metadata": {},
   "source": [
    "### Load ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bf39bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = onnxruntime.InferenceSession(\"model.onnx\")\n",
    "outputs = [o.name for o in session.get_outputs()]\n",
    "inputs = session.get_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0510df25",
   "metadata": {},
   "source": [
    "### Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dd0d902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CARDTXNNBR': 269633690,\n",
       " 'isPinned': 0,\n",
       " 'TXNAMT': 2.0,\n",
       " '2ndLastTrxnAmnt': 1.0,\n",
       " 'scenario1_withoutMerchant': 0,\n",
       " 'scenario1_withMerchant': 0,\n",
       " 'isGoogle': 0,\n",
       " 'isPlayStation': 0,\n",
       " 'isAmazon': 0,\n",
       " 'isApple': 0,\n",
       " 'isMicrosoft': 0,\n",
       " 'isFbPay': 0,\n",
       " 'isCashApp': 0,\n",
       " 'isPaypal': 0,\n",
       " 'isVenmo': 0,\n",
       " 'isWellumpay': 0,\n",
       " 'secanrio3NoOfTrxn': 0,\n",
       " 'secanrio3_Label': 0,\n",
       " 'scenario4_2trxn': 0,\n",
       " 'scenario5_2trxn': 0,\n",
       " 'diffLastTrxn': 0,\n",
       " 'isNewCustomer': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record = pandas_df.to_dict(orient=\"records\")[0]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdfeedd",
   "metadata": {},
   "source": [
    "#### Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cc41b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174 ms ± 3.38 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pandas_inf_df = pd.DataFrame([record])\n",
    "spark_inf_df = spark.createDataFrame(pandas_inf_df)\n",
    "pred = pipeline_model.transform(spark_inf_df)\n",
    "pred_json = pred.toJSON().collect()\n",
    "pred_dict = json.loads(pred_json[0])\n",
    "prediction, probability = pred_dict[\"prediction\"], pred_dict[\"probability\"][\"values\"]\n",
    "# print(f\"Prediction: {prediction}, Probability: {probability}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceee987",
   "metadata": {},
   "source": [
    "#### ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d17882c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21 ms ± 15.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pandas_inf_df = pd.DataFrame([record])\n",
    "input_data= {i.name: v for i, v in zip(inputs, pandas_inf_df.values.reshape(len(inputs),1,1).astype(np.float32))}\n",
    "\n",
    "pred = session.run(output_names = outputs, input_feed=input_data)\n",
    "prediction, probability = [i[0] for i in pred]\n",
    "# print(f\"Prediction: {prediction}, Probability: {probability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d9e404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
