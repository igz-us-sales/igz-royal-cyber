{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Iris Model Training and Deployment Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this demo, we will train and deploy a machine learning model using the iris dataset. We will be using MLRun to create the pipeline. This allows for easy containerization and deployment of our pipeline on top of a production-ready Kubernetes cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The full pipeline will do the following:\n",
    "1. Fetch the dataset and store as a CSV file\n",
    "2. Train the model and log model/metrics/data via experiment tracking hooks\n",
    "3. Deploy the model to a real-time endpoint\n",
    "\n",
    "Once the pipeline is run, we will test the model in real-time via HTTP requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-12-14 20:37:48,047 [info] loaded project spark-pipeline from MLRun DB\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "from mlrun.runtimes.utils import generate_function_image_name\n",
    "\n",
    "project = mlrun.get_or_create_project(name=\"spark-pipeline\", context=\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Docker Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "build = mlrun.new_function(name=\"build-image\", kind=\"remote-spark\")\n",
    "build.spec.build.commands = ['pip install pyspark']\n",
    "build.with_spark_service(spark_service=\"spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT TO BUILD IMAGE - ONLY NEED TO RUN ONCE\n",
    "# build.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".mlrun/func-spark-pipeline-build-image:latest\n"
     ]
    }
   ],
   "source": [
    "image = generate_function_image_name(build)\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Add Functions to Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.remotesparkjob.RemoteSparkRuntime at 0x7ffae983fad0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.set_function(name='get-data', func='components/get_data.py', kind='job', image='mlrun/mlrun')\n",
    "project.set_function(name='spark-read-csv', func='components/spark_read_csv.py', kind='remote-spark', image=image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Add Pipelines to Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "project.set_workflow(name='main', workflow_path='pipelines/training_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Save Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind: project\n",
      "metadata:\n",
      "  name: spark-pipeline\n",
      "  created: '2021-12-14T19:31:48.308000+00:00'\n",
      "spec:\n",
      "  functions:\n",
      "  - url: components/get_data.py\n",
      "    name: get-data\n",
      "    kind: job\n",
      "    image: mlrun/mlrun\n",
      "  - url: components/spark_read_csv.py\n",
      "    name: spark-read-csv\n",
      "    kind: remote-spark\n",
      "    image: .mlrun/func-spark-pipeline-build-image:latest\n",
      "  workflows:\n",
      "  - name: main\n",
      "    path: pipelines/training_pipeline.py\n",
      "    engine: null\n",
      "  artifacts: []\n",
      "  source: ''\n",
      "  subpath: ''\n",
      "  origin_url: ''\n",
      "  desired_state: online\n",
      "  owner: nick\n",
      "  disable_auto_mount: false\n",
      "status:\n",
      "  state: online\n"
     ]
    }
   ],
   "source": [
    "!cat project.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Run Pipeline with Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: kfp Pages: 1 -->\n",
       "<svg width=\"311pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 310.87 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<title>kfp</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-112 306.8731,-112 306.8731,4 -4,4\"/>\n",
       "<!-- spark&#45;pipeline&#45;x7vhp&#45;19177319 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>spark&#45;pipeline&#45;x7vhp&#45;19177319</title>\n",
       "<ellipse fill=\"#00ff00\" stroke=\"#000000\" cx=\"151.4366\" cy=\"-90\" rx=\"96.6831\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"151.4366\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">get&#45;data&#45;prep&#45;data</text>\n",
       "</g>\n",
       "<!-- spark&#45;pipeline&#45;x7vhp&#45;2234529456 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>spark&#45;pipeline&#45;x7vhp&#45;2234529456</title>\n",
       "<ellipse fill=\"#00ff00\" stroke=\"#000000\" cx=\"151.4366\" cy=\"-18\" rx=\"151.3732\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"151.4366\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">spark&#45;read&#45;csv&#45;spark&#45;read&#45;csv</text>\n",
       "</g>\n",
       "<!-- spark&#45;pipeline&#45;x7vhp&#45;19177319&#45;&gt;spark&#45;pipeline&#45;x7vhp&#45;2234529456 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>spark&#45;pipeline&#45;x7vhp&#45;19177319&#45;&gt;spark&#45;pipeline&#45;x7vhp&#45;2234529456</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M151.4366,-71.8314C151.4366,-64.131 151.4366,-54.9743 151.4366,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"154.9367,-46.4132 151.4366,-36.4133 147.9367,-46.4133 154.9367,-46.4132\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7ffae98cf090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Run Results</h2>Workflow b4979e66-170f-4c70-9cb1-f95a8c82f095 finished, state=Succeeded<br>click the hyper links below to see detailed results<br><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>uid</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div title=\"bc24c8c9210647ab945e5c32a728cd9f\"><a href=\"https://dashboard.default-tenant.app.us-sales-32.iguazio-cd0.com/mlprojects/spark-pipeline/jobs/monitor/bc24c8c9210647ab945e5c32a728cd9f/overview\" target=\"_blank\" >...a728cd9f</a></div></td>\n",
       "      <td>Dec 14 20:38:16</td>\n",
       "      <td>completed</td>\n",
       "      <td>spark-read-csv-spark_read_csv</td>\n",
       "      <td></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result\" title=\"files/v3io/projects/spark-pipeline/artifacts/df_sample.csv\">df_sample</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><div title=\"745708f72cb1415d9a1c9682ec1e8f0c\"><a href=\"https://dashboard.default-tenant.app.us-sales-32.iguazio-cd0.com/mlprojects/spark-pipeline/jobs/monitor/745708f72cb1415d9a1c9682ec1e8f0c/overview\" target=\"_blank\" >...ec1e8f0c</a></div></td>\n",
       "      <td>Dec 14 20:37:59</td>\n",
       "      <td>completed</td>\n",
       "      <td>get-data-prep_data</td>\n",
       "      <td><div class=\"dictlist\">num_rows=150</div></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result\" title=\"files/v3io/projects/spark-pipeline/artifacts/cleaned_data.csv\">cleaned_data</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_id = project.run(\n",
    "    name=\"main\",\n",
    "    arguments={\n",
    "        \"source_url\" : \"https://s3.wasabisys.com/iguazio/data/iris/iris.data.raw.csv\",\n",
    "        \"label_column\" : \"label\",\n",
    "    },\n",
    "    watch=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
