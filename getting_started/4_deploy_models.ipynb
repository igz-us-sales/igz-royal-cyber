{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlrun: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudpickle import load\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import mlrun\n",
    "\n",
    "class ClassifierModel(mlrun.serving.V2ModelServer):\n",
    "    def load(self):\n",
    "        \"\"\"load and initialize the model and/or other elements\"\"\"\n",
    "        model_file, extra_data = self.get_model('.pkl')\n",
    "        self.model = load(open(model_file, 'rb'))\n",
    "\n",
    "    def predict(self, body: dict) -> List:\n",
    "        \"\"\"Generate model predictions from sample.\"\"\"\n",
    "        feats = np.asarray(body['inputs'])\n",
    "        result: np.ndarray = self.model.predict(feats)\n",
    "        return result.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlrun: end-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.serving.states.TaskStep at 0x7f083d321a50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import code_to_function, auto_mount\n",
    "\n",
    "serving_fn = code_to_function(\n",
    "    name='model-server',\n",
    "    project=\"royal-cyber\",\n",
    "    kind='serving',\n",
    "    image='mlrun/mlrun'\n",
    ").apply(auto_mount())\n",
    "\n",
    "serving_fn.spec.default_class = 'ClassifierModel'\n",
    "\n",
    "serving_fn.add_model('lr', model_path=\"store://models/royal-cyber/my-training-job-tracking-main_LogisticRegression_model#0:latest@32c8cd1816a14b5eb49d99ab92521b08\")\n",
    "serving_fn.add_model('rf', model_path=\"store://models/royal-cyber/my-training-job-tracking-main_RandomForestClassifier_model#0:latest@32c8cd1816a14b5eb49d99ab92521b08\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-08-20 22:50:08,915 [info] Starting remote function deploy\n",
      "2021-08-20 22:50:09  (info) Deploying function\n",
      "2021-08-20 22:50:09  (info) Building\n",
      "2021-08-20 22:50:09  (info) Staging files and preparing base images\n",
      "2021-08-20 22:50:09  (info) Building processor image\n",
      "2021-08-20 22:50:13  (info) Build complete\n",
      "2021-08-20 22:50:21  (info) Function deploy complete\n",
      "> 2021-08-20 22:50:21,646 [info] function deployed, address=default-tenant.app.us-sales-eks.iguazio-cd0.com:30624\n"
     ]
    }
   ],
   "source": [
    "function_address = serving_fn.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"inputs\": [[5.1, 3.5, 1.4, 0.2], [7.7, 3.8, 6.7, 2.2]]}'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "X_test = [[5.1, 3.5, 1.4, 0.2],[7.7, 3.8, 6.7, 2.2]]\n",
    "data = json.dumps({\"inputs\" : X_test})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'ce315b86-fdd7-4384-9697-c4f9d74459e9', 'model_name': 'lr', 'outputs': [0, 2]}\n",
      "{'id': '8c782ec6-20f7-486d-acb6-104c93e3d323', 'model_name': 'lr', 'outputs': [0, 2]}\n",
      "{'id': '053558c5-ca47-4576-85b6-572b10fe3644', 'model_name': 'rf', 'outputs': [0, 2]}\n",
      "{'id': '83d2ce43-18c7-4bfd-a56d-3f64f8f87e4a', 'model_name': 'rf', 'outputs': [0, 2]}\n"
     ]
    }
   ],
   "source": [
    "for model in [\"lr\", \"rf\"]:\n",
    "    # Inference via serving function\n",
    "    print(serving_fn.invoke(f'/v2/models/{model}/infer', data))\n",
    "    \n",
    "    # Inference via HTTP post request\n",
    "    print(requests.post(url=f\"{function_address}/v2/models/{model}/infer\", data=data).json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
